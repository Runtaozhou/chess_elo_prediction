{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0dc6f9f-8b55-44be-ae9d-6f9a7b41d078",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting the data set Pyspark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a4e3f1-3e97-462f-912c-b565cdf4076d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, split, when, substring\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4372c53e-6a89-4ed4-b383-194c792a843a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/20 10:21:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/20 10:21:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ChessGames\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87134aab-3e2b-47f7-b433-15bf5fc1a679",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6d6446-4e85-44a0-881a-03d66a5a41a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Starting by first converting starting the pieces at their initial positions.\n",
    "# Every game begins like this\n",
    "\n",
    "initial_positions = {\n",
    "    \"Move\": 0,\n",
    "    \"White_Rook_1\": \"a1\",\n",
    "    \"White_Rook_2\": \"h1\",\n",
    "    \"White_Knight_1\": \"b1\",\n",
    "    \"White_Knight_2\": \"g1\",\n",
    "    \"White_Bishop_1\": \"c1\",\n",
    "    \"White_Bishop_2\": \"f1\",\n",
    "    \"White_Queen_1\": \"d1\",\n",
    "    \"White_King_1\": \"e1\",\n",
    "    \"White_Pawn_1\": \"a2\",\n",
    "    \"White_Pawn_2\": \"b2\",\n",
    "    \"White_Pawn_3\": \"c2\",\n",
    "    \"White_Pawn_4\": \"d2\",\n",
    "    \"White_Pawn_5\": \"e2\",\n",
    "    \"White_Pawn_6\": \"f2\",\n",
    "    \"White_Pawn_7\": \"g2\",\n",
    "    \"White_Pawn_8\": \"h2\",\n",
    "    \"Black_Rook_1\": \"a8\",\n",
    "    \"Black_Rook_2\": \"h8\",\n",
    "    \"Black_Knight_1\": \"b8\",\n",
    "    \"Black_Knight_2\": \"g8\",\n",
    "    \"Black_Bishop_1\": \"c8\",\n",
    "    \"Black_Bishop_2\": \"f8\",\n",
    "    \"Black_Queen_1\": \"d8\",\n",
    "    \"Black_King_1\": \"e8\",\n",
    "    \"Black_Pawn_1\": \"a7\",\n",
    "    \"Black_Pawn_2\": \"b7\",\n",
    "    \"Black_Pawn_3\": \"c7\",\n",
    "    \"Black_Pawn_4\": \"d7\",\n",
    "    \"Black_Pawn_5\": \"e7\",\n",
    "    \"Black_Pawn_6\": \"f7\",\n",
    "    \"Black_Pawn_7\": \"g7\",\n",
    "    \"Black_Pawn_8\": \"h7\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa58b69-f0b2-4877-8724-e537304618be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Move</th>\n",
       "      <th>White_Rook_1</th>\n",
       "      <th>White_Rook_2</th>\n",
       "      <th>White_Knight_1</th>\n",
       "      <th>White_Knight_2</th>\n",
       "      <th>White_Bishop_1</th>\n",
       "      <th>White_Bishop_2</th>\n",
       "      <th>White_Queen_1</th>\n",
       "      <th>White_King_1</th>\n",
       "      <th>White_Pawn_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Black_Queen_1</th>\n",
       "      <th>Black_King_1</th>\n",
       "      <th>Black_Pawn_1</th>\n",
       "      <th>Black_Pawn_2</th>\n",
       "      <th>Black_Pawn_3</th>\n",
       "      <th>Black_Pawn_4</th>\n",
       "      <th>Black_Pawn_5</th>\n",
       "      <th>Black_Pawn_6</th>\n",
       "      <th>Black_Pawn_7</th>\n",
       "      <th>Black_Pawn_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a1</td>\n",
       "      <td>h1</td>\n",
       "      <td>b1</td>\n",
       "      <td>g1</td>\n",
       "      <td>c1</td>\n",
       "      <td>f1</td>\n",
       "      <td>d1</td>\n",
       "      <td>e1</td>\n",
       "      <td>a2</td>\n",
       "      <td>...</td>\n",
       "      <td>d8</td>\n",
       "      <td>e8</td>\n",
       "      <td>a7</td>\n",
       "      <td>b7</td>\n",
       "      <td>c7</td>\n",
       "      <td>d7</td>\n",
       "      <td>e7</td>\n",
       "      <td>f7</td>\n",
       "      <td>g7</td>\n",
       "      <td>h7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Move White_Rook_1 White_Rook_2 White_Knight_1 White_Knight_2  \\\n",
       "0     0           a1           h1             b1             g1   \n",
       "\n",
       "  White_Bishop_1 White_Bishop_2 White_Queen_1 White_King_1 White_Pawn_1  ...  \\\n",
       "0             c1             f1            d1           e1           a2  ...   \n",
       "\n",
       "  Black_Queen_1 Black_King_1 Black_Pawn_1 Black_Pawn_2 Black_Pawn_3  \\\n",
       "0            d8           e8           a7           b7           c7   \n",
       "\n",
       "  Black_Pawn_4 Black_Pawn_5 Black_Pawn_6 Black_Pawn_7 Black_Pawn_8  \n",
       "0           d7           e7           f7           g7           h7  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([initial_positions])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8dbcee-539e-4931-9b84-1873e2daa0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Move|next_move|\n",
      "+----+---------+\n",
      "|0   |d2d4     |\n",
      "|1   |e7e6     |\n",
      "|2   |e2e4     |\n",
      "|3   |d7d5     |\n",
      "|4   |e4d5     |\n",
      "|5   |e6d5     |\n",
      "|6   |g1f3     |\n",
      "|7   |f8d6     |\n",
      "|8   |f1d3     |\n",
      "|9   |g8f6     |\n",
      "|10  |e1g1     |\n",
      "|11  |e8g8     |\n",
      "|12  |b2b3     |\n",
      "|13  |c8g4     |\n",
      "|14  |c2c4     |\n",
      "|15  |c7c6     |\n",
      "|16  |c4c5     |\n",
      "|17  |d6c7     |\n",
      "|18  |c1e3     |\n",
      "|19  |f8e8     |\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing this out on the first game!\n",
    "\n",
    "file_path = '/scratch/zrc3hc/filtered_games_total/part-00000-9eb34237-6933-4165-9287-e8441a64b433-c000.json'\n",
    "game_data = []\n",
    "\n",
    "game1_data_df = spark.read.json(file_path)\n",
    "\n",
    "if game1_data_df.count() > 0:\n",
    "    first_game = game1_data_df.limit(1).collect()[0]  # Fetch the first game\n",
    "    moves = first_game[\"Moves\"]  # Extract the moves\n",
    "    for move_number, move in enumerate(moves):\n",
    "        game_data.append({\n",
    "            \"Move\": move_number,\n",
    "            \"next_move\": move  # Record the move in UCI format\n",
    "        })\n",
    "\n",
    "    # Create a PySpark DataFrame for the moves of the first game\n",
    "    game1_moves_df = spark.createDataFrame(game_data)\n",
    "    game1_moves_df.show(truncate=False)\n",
    "else:\n",
    "    print(\"No games found in the file or file is not accessible.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89d31dc-4e0c-457e-b89d-a8cb6a61f47e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------+--------------------+------+--------------------+--------+\n",
      "|BlackElo|      Date|           Event|               Moves|Result|                Site|WhiteElo|\n",
      "+--------+----------+----------------+--------------------+------+--------------------+--------+\n",
      "|    2069|2024.08.01|Rated Blitz game|[d2d4, e7e6, e2e4...|   1-0|https://lichess.o...|    2055|\n",
      "|    2252|2024.08.01|Rated Blitz game|[e2e4, c7c5, b1c3...|   0-1|https://lichess.o...|    2124|\n",
      "|    1972|2024.08.01|Rated Blitz game|[d2d4, d7d5, c2c4...|   0-1|https://lichess.o...|    2010|\n",
      "|    2147|2024.08.01|Rated Blitz game|[e2e4, e7e5, g1f3...|   0-1|https://lichess.o...|    2156|\n",
      "|    2049|2024.08.01|Rated Blitz game|[d2d4, d7d5, g1f3...|   1-0|https://lichess.o...|    2028|\n",
      "|    2091|2024.08.01|Rated Blitz game|[d2d4, d7d5, c2c4...|   0-1|https://lichess.o...|    2072|\n",
      "|    1966|2024.08.01|Rated Blitz game|[e2e4, d7d5, e4d5...|   0-1|https://lichess.o...|    2006|\n",
      "|    2257|2024.08.01|Rated Blitz game|[d2d4, d7d5, c2c4...|   0-1|https://lichess.o...|    2230|\n",
      "|    2221|2024.08.01|Rated Blitz game|[e2e4, c7c5, g1f3...|   1-0|https://lichess.o...|    2176|\n",
      "|    2111|2024.08.01|Rated Blitz game|[e2e4, e7e5, g1f3...|   0-1|https://lichess.o...|    2039|\n",
      "|    2432|2024.08.01|Rated Blitz game|[e2e4, e7e5, g1f3...|   1-0|https://lichess.o...|    2394|\n",
      "|    2496|2024.08.01|Rated Blitz game|[e2e4, e7e5, g1f3...|   0-1|https://lichess.o...|    2521|\n",
      "|    1977|2024.08.01|Rated Blitz game|[b1c3, b7b6, e2e4...|   1-0|https://lichess.o...|    2094|\n",
      "|    2101|2024.08.01|Rated Blitz game|[e2e4, e7e6, d2d4...|   1-0|https://lichess.o...|    2080|\n",
      "|    2035|2024.08.01|Rated Blitz game|[e2e4, c7c5, g1f3...|   1-0|https://lichess.o...|    2040|\n",
      "|    2563|2024.08.01|Rated Blitz game|[e2e4, e7e6, d2d4...|   0-1|https://lichess.o...|    2396|\n",
      "|    2255|2024.08.01|Rated Blitz game|[d2d4, d7d5, g1f3...|   1-0|https://lichess.o...|    2153|\n",
      "|    2033|2024.08.01|Rated Blitz game|[e2e4, c7c5, b1c3...|   0-1|https://lichess.o...|    2009|\n",
      "|    2142|2024.08.01|Rated Blitz game|[e2e4, c7c5, b1c3...|   0-1|https://lichess.o...|    2116|\n",
      "|    2111|2024.08.01|Rated Blitz game|[d2d4, c7c5, e2e3...|   0-1|https://lichess.o...|    2107|\n",
      "+--------+----------+----------------+--------------------+------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "game1_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde47ae7-8c9c-47f1-883c-e97364607682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Move\", IntegerType(), True),\n",
    "    StructField(\"White_Rook_1\", StringType(), True),\n",
    "    StructField(\"White_Rook_2\", StringType(), True),\n",
    "    StructField(\"White_Knight_1\", StringType(), True),\n",
    "    StructField(\"White_Knight_2\", StringType(), True),\n",
    "    StructField(\"White_Bishop_1\", StringType(), True),\n",
    "    StructField(\"White_Bishop_2\", StringType(), True),\n",
    "    StructField(\"White_Queen_1\", StringType(), True),\n",
    "    StructField(\"White_King_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_2\", StringType(), True),\n",
    "    StructField(\"White_Pawn_3\", StringType(), True),\n",
    "    StructField(\"White_Pawn_4\", StringType(), True),\n",
    "    StructField(\"White_Pawn_5\", StringType(), True),\n",
    "    StructField(\"White_Pawn_6\", StringType(), True),\n",
    "    StructField(\"White_Pawn_7\", StringType(), True),\n",
    "    StructField(\"White_Pawn_8\", StringType(), True),\n",
    "    StructField(\"Black_Rook_1\", StringType(), True),\n",
    "    StructField(\"Black_Rook_2\", StringType(), True),\n",
    "    StructField(\"Black_Knight_1\", StringType(), True),\n",
    "    StructField(\"Black_Knight_2\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_1\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_2\", StringType(), True),\n",
    "    StructField(\"Black_Queen_1\", StringType(), True),\n",
    "    StructField(\"Black_King_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_2\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_3\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_4\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_5\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_6\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_7\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_8\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d1e61f-ac21-4cd1-9d31-a537bcbb2347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa01bd00-7f50-49ee-82e2-b294da531d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/20 10:24:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "|Move|White_Rook_1|White_Rook_2|White_Knight_1|White_Knight_2|White_Bishop_1|White_Bishop_2|White_Queen_1|White_King_1|White_Pawn_1|White_Pawn_2|White_Pawn_3|White_Pawn_4|White_Pawn_5|White_Pawn_6|White_Pawn_7|White_Pawn_8|Black_Rook_1|Black_Rook_2|Black_Knight_1|Black_Knight_2|Black_Bishop_1|Black_Bishop_2|Black_Queen_1|Black_King_1|Black_Pawn_1|Black_Pawn_2|Black_Pawn_3|Black_Pawn_4|Black_Pawn_5|Black_Pawn_6|Black_Pawn_7|Black_Pawn_8|\n",
      "+----+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "|   0|          a1|          h1|            b1|            g1|            c1|            f1|           d1|          e1|          a2|          b2|          c2|          d2|          e2|          f2|          g2|          h2|          a8|          h8|            b8|            g8|            c8|            f8|           d8|          e8|          a7|          b7|          c7|          d7|          e7|          f7|          g7|          h7|\n",
      "+----+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+--------------+--------------+--------------+--------------+-------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2abdf5f7-1702-4c7e-bd8d-9c5f6975e4eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 1, Add column 'next_move' (only has to happen once)\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .join(game1_data_df, on=\"Move\", how=\"left\")  # Join on \"Move\"\n",
    ")\n",
    "\n",
    "# Step 2, duplicate row 0 to row 1\n",
    "\n",
    "df_dup = df.union(df.filter(col(\"Move\") == 0).withColumn(\"Move\", col(\"Move\") + 1))\n",
    "\n",
    "# Step 3, Split the 'next_move' column \n",
    "\n",
    "df_split = df_dup.withColumn(\"from_square\", substring(col(\"next_move\"), 1, 2)) \\\n",
    "                 .withColumn(\"to_square\", substring(col(\"next_move\"), 3, 2))\n",
    "\n",
    "# Step 4, Update the new row with information from the previous row\n",
    "\n",
    "columns_to_update = [c for c in df_split.columns if c not in [\"Move\", \"next_move\", \"from_square\", \"to_square\"]]\n",
    "\n",
    "for column in columns_to_update:\n",
    "    df_split = df_split.withColumn(\n",
    "        column,\n",
    "        when(\n",
    "            (col(\"Move\") == 1) & (col(column) == col(\"from_square\")),  # Match `from_square`\n",
    "            col(\"to_square\")  # Update to `to_square`\n",
    "        ).otherwise(col(column))  # Retain the original value otherwise\n",
    "    )\n",
    "\n",
    "# Step 5, Update the 'next_move' in the new row\n",
    "\n",
    "df_split = (\n",
    "    df_split\n",
    "    .join(game1_data_df, on=\"Move\", how=\"left\")  # Join on \"Move\"\n",
    "    .drop(game1_data_df[\"next_move\"])  # Drop the `next_move` column from game1_data_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cbee6ee-d748-497a-9d2f-437ee611e657",
   "metadata": {
    "tags": []
   },
   "source": [
    "df_split.select(\"Move\", \"next_move\", \"from_square\", \"to_square\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcce52ae-d8a4-41cb-af85-f806e984710b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([initial_positions])\n",
    "\n",
    "df = spark.createDataFrame(df, schema=schema)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59a08eaf-a432-4a20-b48b-2a0c486d5b5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "df_split.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d02b53c0-efc8-48e0-b2e4-07a97959786b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `Move` cannot be resolved on the right side of the join. The right-side columns: [`BlackElo`, `Date`, `Event`, `Moves`, `Result`, `Site`, `WhiteElo`].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1, initialize the dataframe\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame1_data_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMove\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Loop through the first 10 moves\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m10\u001b[39m, game1_data_df\u001b[38;5;241m.\u001b[39mcount())):  \n\u001b[1;32m      8\u001b[0m     \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Step 2: Duplicate the previous row\u001b[39;00m\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/site-packages/pyspark/sql/dataframe.py:2344\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jseq([])\n\u001b[1;32m   2343\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(how, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2344\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `Move` cannot be resolved on the right side of the join. The right-side columns: [`BlackElo`, `Date`, `Event`, `Moves`, `Result`, `Site`, `WhiteElo`]."
     ]
    }
   ],
   "source": [
    "# Step 1, initialize the dataframe\n",
    "\n",
    "df = df.join(game1_data_df, on=\"Move\", how=\"left\")\n",
    "\n",
    "# Loop through the first 10 moves\n",
    "\n",
    "for move in range(1, min(10, game1_data_df.count())):  \n",
    "    \n",
    "    # Step 2: Duplicate the previous row\n",
    "    \n",
    "    previous_row = df.filter(col(\"Move\") == move - 1)\n",
    "    new_row = previous_row.withColumn(\"Move\", col(\"Move\") + 1)\n",
    "    \n",
    "    # Step 3: Split the 'next_move' column into 'from_square' and 'to_square'\n",
    "    \n",
    "    new_row = new_row.withColumn(\"from_square\", substring(col(\"next_move\"), 1, 2)) \\\n",
    "                     .withColumn(\"to_square\", substring(col(\"next_move\"), 3, 2))\n",
    "    \n",
    "    # Step 4a: Check if `to_square` is already present in the new row\n",
    "    \n",
    "    # If it is, it means a piece was captured, so update the piece at `from_square` to `0`\n",
    "    \n",
    "    columns_to_check = [c for c in df.columns if c not in [\"Move\", \"next_move\", \"from_square\", \"to_square\"]]\n",
    "    for column in columns_to_check:\n",
    "        new_row = new_row.withColumn(\n",
    "            column,\n",
    "            when(\n",
    "                (col(\"to_square\") == col(column)),  # Check if `to_square` matches any current column value\n",
    "                \"0\"  # Set the piece at `to_square` to `0` to indicate it was captured\n",
    "            ).otherwise(col(column))  # Retain the original value otherwise\n",
    "        )\n",
    "    \n",
    "    # Step 4b: Update the piece positions for the new row\n",
    "    for column in columns_to_check:\n",
    "        new_row = new_row.withColumn(\n",
    "            column,\n",
    "            when(\n",
    "                (col(\"Move\") == move) & (col(column) == col(\"from_square\")),  # Match `from_square`\n",
    "                col(\"to_square\")  # Update to `to_square`\n",
    "            ).otherwise(col(column))  # Retain the original value otherwise\n",
    "        )\n",
    "        \n",
    "    # Step 5: Update the 'Next Move' by mapping\n",
    "    \n",
    "    new_row = new_row.join(game1_data_df, on = \"Move\", how = \"left\")\n",
    "    \n",
    "    new_row = new_row.drop(game1_data_df[\"next_move\"])\n",
    "    \n",
    "    new_row = new_row.select(df.columns)  # Select only the columns present in `df` to makesure there no duplicates \n",
    "    \n",
    "    df = df.union(new_row)\n",
    "    \n",
    "    print(f\"{move} moves processed...\")\n",
    "\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a89c61b-ef75-4ae8-9c8d-5183ec495378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Move|next_move|\n",
      "+----+---------+\n",
      "|0   |e2e4     |\n",
      "|1   |c7c6     |\n",
      "|2   |c2c4     |\n",
      "|3   |d7d5     |\n",
      "|4   |c4d5     |\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Move\", \"next_move\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
