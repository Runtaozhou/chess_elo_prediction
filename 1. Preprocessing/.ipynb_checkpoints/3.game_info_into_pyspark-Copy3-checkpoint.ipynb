{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0dc6f9f-8b55-44be-ae9d-6f9a7b41d078",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting the data set Pyspark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a4e3f1-3e97-462f-912c-b565cdf4076d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/27 16:00:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/27 16:00:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, split, when, substring, lit\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Start a new SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ChessDataProcessing\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"64g\") \\\n",
    "    .config(\"spark.executor.memory\", \"64g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.codegen.maxFields\", \"2000\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87134aab-3e2b-47f7-b433-15bf5fc1a679",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8013a24-2ff3-45ef-ab91-e9628a2601eb",
   "metadata": {},
   "source": [
    "# Run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6d6446-4e85-44a0-881a-03d66a5a41a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Starting by first converting starting the pieces at their initial positions.\n",
    "# Every game begins like this\n",
    " \n",
    "initial_positions = {\n",
    "    \"Move\": 0,\n",
    "    \"White_Rook_1\": \"a1\",\n",
    "    \"White_Rook_2\": \"h1\",\n",
    "    \"White_Knight_1\": \"b1\",\n",
    "    \"White_Knight_2\": \"g1\",\n",
    "    \"White_Bishop_1\": \"c1\",\n",
    "    \"White_Bishop_2\": \"f1\",\n",
    "    \"White_Queen_1\": \"d1\",\n",
    "    \"White_King_1\": \"e1\",\n",
    "    \"White_Pawn_1\": \"a2\",\n",
    "    \"White_Pawn_2\": \"b2\",\n",
    "    \"White_Pawn_3\": \"c2\",\n",
    "    \"White_Pawn_4\": \"d2\",\n",
    "    \"White_Pawn_5\": \"e2\",\n",
    "    \"White_Pawn_6\": \"f2\",\n",
    "    \"White_Pawn_7\": \"g2\",\n",
    "    \"White_Pawn_8\": \"h2\",\n",
    "    \"Black_Rook_1\": \"a8\",\n",
    "    \"Black_Rook_2\": \"h8\",\n",
    "    \"Black_Knight_1\": \"b8\",\n",
    "    \"Black_Knight_2\": \"g8\",\n",
    "    \"Black_Bishop_1\": \"c8\",\n",
    "    \"Black_Bishop_2\": \"f8\",\n",
    "    \"Black_Queen_1\": \"d8\",\n",
    "    \"Black_King_1\": \"e8\",\n",
    "    \"Black_Pawn_1\": \"a7\",\n",
    "    \"Black_Pawn_2\": \"b7\",\n",
    "    \"Black_Pawn_3\": \"c7\",\n",
    "    \"Black_Pawn_4\": \"d7\",\n",
    "    \"Black_Pawn_5\": \"e7\",\n",
    "    \"Black_Pawn_6\": \"f7\",\n",
    "    \"Black_Pawn_7\": \"g7\",\n",
    "    \"Black_Pawn_8\": \"h7\",\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([initial_positions])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d00f4940-7f4e-4336-8de8-d3ad3eab5594",
   "metadata": {
    "tags": []
   },
   "source": [
    "file_path = '/scratch/zrc3hc/filtered_games_total/part-00000-9eb34237-6933-4165-9287-e8441a64b433-c000.json'\n",
    "games_df = spark.read.json(file_path)\n",
    "\n",
    "if games_df.count() > 0:\n",
    "    combined_game_data = []  # store data for all games\n",
    "\n",
    "    # Loop through each game\n",
    "    for game_id, game in enumerate(games_df.collect()):\n",
    "        moves = game[\"Moves\"]  # extract the moves from the given game\n",
    "        result = game[\"Result\"]  # extrace the result from the given game\n",
    "        game_data = [] \n",
    "        \n",
    "        for move_number, move in enumerate(moves):\n",
    "            game_data.append({\n",
    "                \"game_id\": game_id,\n",
    "                \"Move\": move_number,\n",
    "                \"next_move\": move,\n",
    "                \"result\": result \n",
    "            })\n",
    "        \n",
    "        combined_game_data.extend(game_data)\n",
    "    \n",
    "    # Create a single PySpark DataFrame for all games\n",
    "    combined_games_df = spark.createDataFrame(combined_game_data)\n",
    "    combined_games_df.show(truncate=False)\n",
    "else:\n",
    "    print(\"No games found in the file or file is not accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337fda20-b975-4854-bbe5-5233edc719b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Saving and or upload combined games data...\n",
    "file_path_saved_games = '/scratch/zrc3hc/combined_games.csv'\n",
    "#combined_games_df.write.csv(file_path, header=True, mode=\"overwrite\")\n",
    "combined_games_df = spark.read.csv(file_path_saved_games, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd4c448-f804-4315-819b-f27417a52045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+------+\n",
      "|Move|game_id|next_move|result|\n",
      "+----+-------+---------+------+\n",
      "|   0|     10|     e2e4|   1-0|\n",
      "|   1|     10|     e7e5|   1-0|\n",
      "|   2|     10|     g1f3|   1-0|\n",
      "|   3|     10|     g8f6|   1-0|\n",
      "|   4|     10|     d2d4|   1-0|\n",
      "|   5|     10|     f6e4|   1-0|\n",
      "|   6|     10|     d4e5|   1-0|\n",
      "|   7|     10|     f8c5|   1-0|\n",
      "|   8|     10|     f1c4|   1-0|\n",
      "|   9|     10|     c5f2|   1-0|\n",
      "+----+-------+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_games_df.filter(combined_games_df.game_id == 10).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f2512-867f-43ea-9800-58dc26d09e3b",
   "metadata": {},
   "source": [
    "# Run This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde47ae7-8c9c-47f1-883c-e97364607682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Move\", IntegerType(), True),\n",
    "    StructField(\"White_Rook_1\", StringType(), True),\n",
    "    StructField(\"White_Rook_2\", StringType(), True),\n",
    "    StructField(\"White_Knight_1\", StringType(), True),\n",
    "    StructField(\"White_Knight_2\", StringType(), True),\n",
    "    StructField(\"White_Bishop_1\", StringType(), True),\n",
    "    StructField(\"White_Bishop_2\", StringType(), True),\n",
    "    StructField(\"White_Queen_1\", StringType(), True),\n",
    "    StructField(\"White_King_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_2\", StringType(), True),\n",
    "    StructField(\"White_Pawn_3\", StringType(), True),\n",
    "    StructField(\"White_Pawn_4\", StringType(), True),\n",
    "    StructField(\"White_Pawn_5\", StringType(), True),\n",
    "    StructField(\"White_Pawn_6\", StringType(), True),\n",
    "    StructField(\"White_Pawn_7\", StringType(), True),\n",
    "    StructField(\"White_Pawn_8\", StringType(), True),\n",
    "    StructField(\"Black_Rook_1\", StringType(), True),\n",
    "    StructField(\"Black_Rook_2\", StringType(), True),\n",
    "    StructField(\"Black_Knight_1\", StringType(), True),\n",
    "    StructField(\"Black_Knight_2\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_1\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_2\", StringType(), True),\n",
    "    StructField(\"Black_Queen_1\", StringType(), True),\n",
    "    StructField(\"Black_King_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_2\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_3\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_4\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_5\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_6\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_7\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_8\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14823e05-8b77-4653-8795-0bdf436aec90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"Move\", IntegerType(), True),\n",
    "    StructField(\"White_Rook_1\", StringType(), True),\n",
    "    StructField(\"White_Rook_2\", StringType(), True),\n",
    "    StructField(\"White_Knight_1\", StringType(), True),\n",
    "    StructField(\"White_Knight_2\", StringType(), True),\n",
    "    StructField(\"White_Bishop_1\", StringType(), True),\n",
    "    StructField(\"White_Bishop_2\", StringType(), True),\n",
    "    StructField(\"White_Queen_1\", StringType(), True),\n",
    "    StructField(\"White_King_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_1\", StringType(), True),\n",
    "    StructField(\"White_Pawn_2\", StringType(), True),\n",
    "    StructField(\"White_Pawn_3\", StringType(), True),\n",
    "    StructField(\"White_Pawn_4\", StringType(), True),\n",
    "    StructField(\"White_Pawn_5\", StringType(), True),\n",
    "    StructField(\"White_Pawn_6\", StringType(), True),\n",
    "    StructField(\"White_Pawn_7\", StringType(), True),\n",
    "    StructField(\"White_Pawn_8\", StringType(), True),\n",
    "    StructField(\"Black_Rook_1\", StringType(), True),\n",
    "    StructField(\"Black_Rook_2\", StringType(), True),\n",
    "    StructField(\"Black_Knight_1\", StringType(), True),\n",
    "    StructField(\"Black_Knight_2\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_1\", StringType(), True),\n",
    "    StructField(\"Black_Bishop_2\", StringType(), True),\n",
    "    StructField(\"Black_Queen_1\", StringType(), True),\n",
    "    StructField(\"Black_King_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_1\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_2\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_3\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_4\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_5\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_6\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_7\", StringType(), True),\n",
    "    StructField(\"Black_Pawn_8\", StringType(), True),\n",
    "    StructField(\"game_id\", StringType(), True),\n",
    "    StructField(\"next_move\", StringType(), True),\n",
    "    StructField(\"result\", IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0272b1ba-8d64-43bb-83ab-ff6b667243e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the game ids! \n",
    "game_ids = [row[\"game_id\"] for row in combined_games_df.select(\"game_id\").distinct().collect()[2000:2500]]\n",
    "len(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c20b64-cf04-4c02-8baa-77d47adbc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c3d00-b8d5-41a9-aad5-84136caa8cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1dda9c-500a-47e6-81ef-89070088d8b2",
   "metadata": {},
   "source": [
    "# It's here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae7fb42-ca17-4db1-9ffe-ad2acd7e3b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chess_squares = [\n",
    "    \"a1\", \"b1\", \"c1\", \"d1\", \"e1\", \"f1\", \"g1\", \"h1\",\n",
    "    \"a2\", \"b2\", \"c2\", \"d2\", \"e2\", \"f2\", \"g2\", \"h2\",\n",
    "    \"a3\", \"b3\", \"c3\", \"d3\", \"e3\", \"f3\", \"g3\", \"h3\",\n",
    "    \"a4\", \"b4\", \"c4\", \"d4\", \"e4\", \"f4\", \"g4\", \"h4\",\n",
    "    \"a5\", \"b5\", \"c5\", \"d5\", \"e5\", \"f5\", \"g5\", \"h5\",\n",
    "    \"a6\", \"b6\", \"c6\", \"d6\", \"e6\", \"f6\", \"g6\", \"h6\",\n",
    "    \"a7\", \"b7\", \"c7\", \"d7\", \"e7\", \"f7\", \"g7\", \"h7\",\n",
    "    \"a8\", \"b8\", \"c8\", \"d8\", \"e8\", \"f8\", \"g8\", \"h8\"\n",
    "]\n",
    "\n",
    "# Define the schema\n",
    "schema3 = StructType([\n",
    "    StructField(\"Move\", IntegerType(), True),\n",
    "    StructField(\"game_id\", IntegerType(), True),\n",
    "    StructField(\"next_move\", StringType(), True),\n",
    "    StructField(\"result\", StringType(), True),\n",
    "    *[\n",
    "        StructField(square, IntegerType(), True)  # Each chess square is an integer field\n",
    "        for square in chess_squares\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9458c73-0eda-414b-b3de-0f04197b6ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_squares(row, piece, value, chess_squares):\n",
    "    for square in chess_squares:\n",
    "        if row[piece] == square:\n",
    "            row[square] = value\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d6b7dfd-54b9-4398-939f-927a1462fe31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99997"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46402ad5-f1e8-46dc-95a2-6ff736ceec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Game ID: 763, total moves: 143\n",
      "Processing Move: 0\n",
      "Processing Move: 15\n",
      "Processing Move: 30\n",
      "Processing Move: 45\n",
      "Processing Move: 60\n",
      "Processing Move: 75\n",
      "Processing Move: 90\n",
      "Processing Move: 105\n",
      "Processing Move: 120\n",
      "Processing Move: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:11:29 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/11/27 16:12:46 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 1 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:14:43 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:16:42 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:18:42 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 4 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:20:46 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:22:52 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 6 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:25:00 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 7 rows\n",
      "Processing Game ID: 816, total moves: 44\n",
      "Processing Move: 0\n",
      "Processing Move: 15\n",
      "Processing Move: 30\n",
      "Saved Games Final Updated: 8 rows\n",
      "Saved Games Final Updated: 9 rows\n",
      "Processing Game ID: 924, total moves: 25\n",
      "Processing Move: 0\n",
      "Processing Move: 15\n",
      "Saved Games Final Updated: 10 rows\n",
      "Processing Game ID: 1147, total moves: 72\n",
      "Processing Move: 0\n",
      "Processing Move: 15\n",
      "Processing Move: 30\n",
      "Processing Move: 45\n",
      "Processing Move: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:26:51 WARN DAGScheduler: Broadcasting large task binary with size 1335.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 11 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:27:21 WARN DAGScheduler: Broadcasting large task binary with size 1354.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 12 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:27:53 WARN DAGScheduler: Broadcasting large task binary with size 1373.2 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 13 rows\n",
      "Processing Game ID: 1484, total moves: 81\n",
      "Processing Move: 0\n",
      "Processing Move: 15\n",
      "Processing Move: 30\n",
      "Processing Move: 45\n",
      "Processing Move: 60\n",
      "Processing Move: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 16:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1485.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Games Final Updated: 14 rows\n"
     ]
    }
   ],
   "source": [
    "output_file = '/home/zrc3hc/Chess/1. Preprocessing/saved_games_final4.csv'\n",
    "\n",
    "# Blank canvas for each game\n",
    "df = pd.DataFrame([initial_positions])\n",
    "\n",
    "df = spark.createDataFrame(df, schema=schema)\n",
    "\n",
    "saved_games = spark.createDataFrame([], schema = schema3)\n",
    "\n",
    "#game_ids = [row[\"game_id\"] for row in combined_games_df.select(\"game_id\").distinct().collect()]\n",
    "\n",
    "saved_games_final = pd.DataFrame()\n",
    "\n",
    "\n",
    "# initializing the board\n",
    "\n",
    "piece_to_value = {\n",
    "    \"White_Rook_1\": 5, \"White_Rook_2\": 5,\n",
    "    \"White_Knight_1\": 3, \"White_Knight_2\": 3,\n",
    "    \"White_Bishop_1\": 3, \"White_Bishop_2\": 3,\n",
    "    \"White_Queen_1\": 9,\n",
    "    \"White_King_1\": 10, \n",
    "    \"White_Pawn_1\": 1, \"White_Pawn_2\": 1, \"White_Pawn_3\": 1, \"White_Pawn_4\": 1,\n",
    "    \"White_Pawn_5\": 1, \"White_Pawn_6\": 1, \"White_Pawn_7\": 1, \"White_Pawn_8\": 1,\n",
    "    \"Black_Rook_1\": -5, \"Black_Rook_2\": -5,\n",
    "    \"Black_Knight_1\": -3, \"Black_Knight_2\": -3,\n",
    "    \"Black_Bishop_1\": -3, \"Black_Bishop_2\": -3,\n",
    "    \"Black_Queen_1\": -9,\n",
    "    \"Black_King_1\": -10, \n",
    "    \"Black_Pawn_1\": -1, \"Black_Pawn_2\": -1, \"Black_Pawn_3\": -1, \"Black_Pawn_4\": -1,\n",
    "    \"Black_Pawn_5\": -1, \"Black_Pawn_6\": -1, \"Black_Pawn_7\": -1, \"Black_Pawn_8\": -1\n",
    "}\n",
    "\n",
    "chess_squares = [\n",
    "    \"a1\", \"b1\", \"c1\", \"d1\", \"e1\", \"f1\", \"g1\", \"h1\",\n",
    "    \"a2\", \"b2\", \"c2\", \"d2\", \"e2\", \"f2\", \"g2\", \"h2\",\n",
    "    \"a3\", \"b3\", \"c3\", \"d3\", \"e3\", \"f3\", \"g3\", \"h3\",\n",
    "    \"a4\", \"b4\", \"c4\", \"d4\", \"e4\", \"f4\", \"g4\", \"h4\",\n",
    "    \"a5\", \"b5\", \"c5\", \"d5\", \"e5\", \"f5\", \"g5\", \"h5\",\n",
    "    \"a6\", \"b6\", \"c6\", \"d6\", \"e6\", \"f6\", \"g6\", \"h6\",\n",
    "    \"a7\", \"b7\", \"c7\", \"d7\", \"e7\", \"f7\", \"g7\", \"h7\",\n",
    "    \"a8\", \"b8\", \"c8\", \"d8\", \"e8\", \"f8\", \"g8\", \"h8\"\n",
    "]\n",
    "\n",
    "\n",
    " \n",
    "saved_games = df_combined = spark.createDataFrame([], schema1)\n",
    "\n",
    "for game_id in game_ids:\n",
    "    \n",
    "    current_game_info = combined_games_df.filter(combined_games_df.game_id == game_id)\n",
    "    \n",
    "    # Step 1. First, calculate which rows we will be saving (only the last 10 percent of each game...)\n",
    "\n",
    "    next_moves = [row[\"next_move\"] for row in current_game_info.select(\"next_move\").collect()]\n",
    "\n",
    "    total_moves = current_game_info.count()\n",
    "\n",
    "    number_of_moves = int(total_moves * .05)\n",
    "\n",
    "    moves_captured_range = range(total_moves - number_of_moves, total_moves)\n",
    "    \n",
    "    print(f\"Processing Game ID: {game_id}, total moves: {total_moves}\")\n",
    "\n",
    "    # Step 2. Denote the previous row\n",
    "\n",
    "    current_game = df.join(current_game_info, on=\"Move\", how=\"left\")\n",
    "\n",
    "    # removing duplicate columns\n",
    "\n",
    "    current_game = current_game.select(*(col for col in current_game.columns if current_game.columns.count(col) == 1))\n",
    "          \n",
    "    # Reset move count for each game \n",
    "    move_count = 0\n",
    "\n",
    "    previous_row = current_game.filter(col(\"Move\") == move_count)\n",
    "\n",
    "    next_moves = [row[\"next_move\"] for row in current_game_info.select(\"next_move\").collect()]\n",
    "\n",
    "    row_list = []\n",
    "    \n",
    "    for move in range(0, total_moves - 1): \n",
    "        \n",
    "        if move % 15 == 0:\n",
    "\n",
    "            print(f\"Processing Move: {move}\")\n",
    "\n",
    "        # Step 2: Duplicate the previous row\n",
    "\n",
    "        new_row = previous_row.withColumn(\"Move\", col(\"Move\") + 1)\n",
    "\n",
    "        # Step 3: Split 'next_move' into 'from_square' and 'to_square'\n",
    "\n",
    "        new_row = new_row.withColumn(\"from_square\", substring(col(\"next_move\"), 1, 2)) \\\n",
    "                         .withColumn(\"to_square\", substring(col(\"next_move\"), 3, 2))\n",
    "\n",
    "        # Step 4a: Update the piece positions based on 'to_square'\n",
    "        columns_to_check = [c for c in current_game.columns if c not in [\"Move\", \"next_move\", \"from_square\", \"to_square\", \"game_id\", \"result\"]]\n",
    "        new_row = new_row.select(\n",
    "            *[\n",
    "                when(col(\"to_square\") == col(column), \"0\").otherwise(col(column)).alias(column)\n",
    "                if column in columns_to_check else col(column)\n",
    "                for column in new_row.columns\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Step 4b: Update the piece positions based on 'from_square'\n",
    "        new_row = new_row.select(\n",
    "            *[\n",
    "                when(col(column) == col(\"from_square\"), col(\"to_square\")).otherwise(col(column)).alias(column)\n",
    "                if column in columns_to_check else col(column)\n",
    "                for column in new_row.columns\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Step 5: Update the 'Next Move'\n",
    "        move_count += 1\n",
    "        new_row = new_row.withColumn(\"Move\", lit(move_count)).drop(\"from_square\", \"to_square\")\n",
    "        if move + 1 < len(next_moves):\n",
    "            new_row = new_row.withColumn(\"next_move\", lit(next_moves[move + 1]))\n",
    "        else:\n",
    "            new_row = new_row.withColumn(\"next_move\", lit(None))\n",
    "            print(\"Ran out of moves\")\n",
    "            print(move)\n",
    "\n",
    "        previous_row = new_row\n",
    "\n",
    "        if move_count in moves_captured_range:\n",
    "            pandas_df = new_row.toPandas()\n",
    "\n",
    "            for square in chess_squares:\n",
    "                pandas_df[square] = 0\n",
    "\n",
    "            # Update chess squares based on piece positions\n",
    "            for piece, value in piece_to_value.items():\n",
    "                pandas_df = pandas_df.apply(\n",
    "                    lambda row: update_squares(row, piece, value, chess_squares),\n",
    "                    axis=1\n",
    "            )\n",
    "\n",
    "            pandas_df = pandas_df.drop(columns=list(piece_to_value.keys()))\n",
    "\n",
    "            saved_games_final = pd.concat([saved_games_final, pandas_df], ignore_index=True)\n",
    "            print(f\"Saved Games Final Updated: {saved_games_final.shape[0]} rows\")\n",
    "            \n",
    "            # Save intermediate results\n",
    "            \n",
    "            saved_games_final.to_csv(output_file, index = False)\n",
    "\n",
    "print(\"Final DataFrame:\")\n",
    "print(saved_games_final)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "101a993d-bee3-421e-814c-e411fa7c9de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = '/home/zrc3hc/Chess/1. Preprocessing/saved_games_final1.csv'\n",
    "\n",
    "saved_games_final.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
